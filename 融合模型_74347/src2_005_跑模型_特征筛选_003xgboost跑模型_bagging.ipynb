{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir227 = './features_227/'\n",
    "features_dir306 = './features_306/'\n",
    "data_dir = \"./data/FT_Camp_2/\"\n",
    "inter_dir = \"./inter_data_repo/2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据\n",
    "train227 = pd.read_csv(data_dir + 'train.csv')\n",
    "\n",
    "# 预测目标用户\n",
    "pred_users306 = pd.read_csv(data_dir + 'pred_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random_seed = list(range(43))\n",
    "max_depth = [3,4]\n",
    "lambd = list(range(0,5))\n",
    "subsample = [i/1000.0 for i in range(700,800)]\n",
    "colsample_bytree = [i/1000.0 for i in range(700,800)]\n",
    "min_child_weight = [i/100.0 for i in range(150,250)]\n",
    "# n_feature = range(150,282,2)\n",
    "\n",
    "random.shuffle(random_seed)\n",
    "random.shuffle(max_depth)\n",
    "random.shuffle(lambd)\n",
    "random.shuffle(subsample)\n",
    "random.shuffle(colsample_bytree)\n",
    "random.shuffle(min_child_weight)\n",
    "# random.shuffle(n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(random_seed, open(inter_dir + 'random_seed_'+str(iteration)+'.p', 'wb'))\n",
    "pickle.dump(max_depth, open(inter_dir + 'max_depth_'+str(iteration)+'.p', 'wb'))\n",
    "pickle.dump(lambd, open(inter_dir + 'lambd_'+str(iteration)+'.p', 'wb'))\n",
    "pickle.dump(subsample, open(inter_dir + 'subsample_'+str(iteration)+'.p', 'wb'))\n",
    "pickle.dump(colsample_bytree, open(inter_dir + 'colsample_bytree_'+str(iteration)+'.p', 'wb'))\n",
    "pickle.dump(min_child_weight, open(inter_dir + 'min_child_weight_'+str(iteration)+'.p', 'wb'))\n",
    "# pickle.dump(random_seed, open(inter_dir + 'random_seed_'+str(iteration)+'.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X227 = pickle.load(open(inter_dir + 'X227.p', 'rb'))\n",
    "X306 = pickle.load( open(inter_dir + 'X306.p', 'rb'))\n",
    "\n",
    "Y227 = pickle.load(open(inter_dir + 'Y227.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X306 = X306[list(X227.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X227.columns == X306.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X227_csr = sparse.csr_matrix(X227)\n",
    "X306_csr = sparse.csr_matrix(X306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X227_csr = sparse.csr_matrix(X227.loc[:,sfeatures])\n",
    "# X306_csr = sparse.csr_matrix(X306.loc[:,sfeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108252, 694)\n",
      "(94655, 694)\n"
     ]
    }
   ],
   "source": [
    "print(X227_csr.shape)\n",
    "print(X306_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pipeline(iteration,random_seed,max_depth,lambd,subsample,colsample_bytree,min_child_weight):\n",
    "    \n",
    "#     X_train, y_train = X227_csr, Y227\n",
    "#     if max_depth==3:\n",
    "#         n_estimators = 400\n",
    "#     elif max_depth==4:\n",
    "#         n_estimators = 300\n",
    "\n",
    "#     model = xgb.XGBClassifier(n_estimators=n_estimators,\n",
    "#                               max_depth = max_depth,\n",
    "#                               reg_lambda = lambd,\n",
    "#                               subsample = subsample,\n",
    "#                               colsample_bytree = colsample_bytree,\n",
    "#                               min_child_weight = min_child_weight,\n",
    "#                               n_jobs = 6,\n",
    "#                               random_state=random_seed)\n",
    "#     eval_set = [(X_train, y_train)]\n",
    "#     models.fit(X_train, y_train, eval_metric=['auc'], eval_set=eval_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(iteration,random_seed,max_depth,lambd,subsample,colsample_bytree,min_child_weight):\n",
    "    if max_depth==3:\n",
    "        n_estimators = 400\n",
    "    elif max_depth==4:\n",
    "        n_estimators = 300\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    preds306 = np.zeros((X306_csr.shape[0]))\n",
    "    i = 0\n",
    "    models = [0]*kf.get_n_splits()\n",
    "    roc_scores = []\n",
    "    for train_index, val_index in kf.split(X227_csr, Y227):\n",
    "        X_train, X_val = X227_csr[train_index], X227_csr[val_index]\n",
    "        y_train, y_val = Y227[train_index], Y227[val_index]\n",
    "        eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "\n",
    "        models[i] = xgb.XGBClassifier(n_estimators=n_estimators,\n",
    "                              max_depth = max_depth,\n",
    "                              reg_lambda = lambd,\n",
    "                              subsample = subsample,\n",
    "                              colsample_bytree = colsample_bytree,\n",
    "                              min_child_weight = min_child_weight,\n",
    "                              n_jobs = 6,\n",
    "                              random_state=random_seed)\n",
    "        models[i].fit(X_train, y_train, eval_metric=['auc', \"error\", \"logloss\"], eval_set=eval_set, verbose=False)\n",
    "\n",
    "        score = models[i].predict_proba(X_val)[:, 1]\n",
    "\n",
    "        roc = roc_auc_score(y_val, score)\n",
    "        roc_scores.append(roc)\n",
    "\n",
    "        print(roc)\n",
    "\n",
    "        preds306 = preds306 + models[i].predict_proba(X306_csr)[:,1]\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    preds306 = preds306 / kf.get_n_splits()\n",
    "    pickle.dump(preds306, open(inter_dir + 'preds306_'+str(iteration)+'.p', 'wb'))\n",
    "    pickle.dump(models, open(inter_dir + 'models_'+str(iteration)+'.p','wb'))\n",
    "    pickle.dump(roc_scores, open(inter_dir + 'roc_scores_'+str(iteration)+'.p','wb'))\n",
    "    print(\"mean_roc_score: {}\".format(np.mean(roc_scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "12 4 1 0.724 0.752 1.64\n",
      "0.6963155052551382\n",
      "0.6988293898152477\n",
      "0.6977228138528138\n",
      "0.6962828896103896\n",
      "0.6946056060606061\n",
      "mean_roc_score: 0.6967512409188391\n",
      "iter: 1\n",
      "19 3 4 0.708 0.731 1.61\n",
      "0.7005322126123319\n",
      "0.7001805642131145\n",
      "0.6981005735930735\n",
      "0.6968932575757576\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,30):\n",
    "    print (\"iter:\",i)\n",
    "    print(random_seed[i],max_depth[i%2],lambd[i%5],subsample[i],colsample_bytree[i],min_child_weight[i])\n",
    "    pipeline(i,random_seed[i],max_depth[i%2],lambd[i%5],subsample[i],colsample_bytree[i],min_child_weight[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(kf.get_n_splits()):\n",
    "#     results = models[i].evals_result()\n",
    "#     print(len(results['validation_0']['auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
